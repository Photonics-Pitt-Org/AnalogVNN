{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# AnalogVNN Demo/Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04QgGZc9bF5D"
   },
   "source": [
    "#### To create 3 layered linear photonic analog neural network with 4-bit precision, 0.2 leakage and clamp normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Copyright 2021-present Vivswan Shah (vivswanshah@pitt.edu)\n",
    "\n",
    "[![arXiv](https://img.shields.io/badge/arXiv-2210.10048-orange.svg)](https://arxiv.org/abs/2210.10048)\n",
    "[![PyPI version](https://badge.fury.io/py/analogvnn.svg)](https://badge.fury.io/py/analogvnn)\n",
    "[![Documentation Status](https://readthedocs.org/projects/analogvnn/badge/?version=stable)](https://analogvnn.readthedocs.io/en/stable/?badge=stable)\n",
    "[![Python](https://img.shields.io/badge/python-3.7--3.11-blue)](https://badge.fury.io/py/analogvnn)\n",
    "[![License: MPL 2.0](https://img.shields.io/badge/License-MPL_2.0-blue.svg)](https://opensource.org/licenses/MPL-2.0)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://analogvnn.readthedocs.io/en/v1.0.0/tutorial.html\"><img src=\"https://analogvnn.readthedocs.io/en/in_progess/_static/analogvnn-logo-square-black.svg\" height=\"32px\" />View on AnalogVNN</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Vivswan/AnalogVNN/blob/v1.0.0/docs/_static/AnalogVNN_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/Vivswan/AnalogVNN/blob/v1.0.0/docs/_static/AnalogVNN_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/Vivswan/AnalogVNN/raw/v1.0.0/docs/_static/AnalogVNN_Demo.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnrWf3PCEzXL"
   },
   "source": [
    "## Setting up the Enviroment AnalogVNN"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Install AnalogVNN with Pip\n",
    "!pip install analogvnn"
   ],
   "metadata": {
    "id": "812kuN10TZgu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import analogvnn\n",
    "\n",
    "import torch.backends.cudnn\n",
    "import torchvision\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "from analogvnn.nn.Linear import Linear\n",
    "from analogvnn.nn.activation.Gaussian import GeLU\n",
    "from analogvnn.nn.module.FullSequential import FullSequential\n",
    "from analogvnn.nn.noise.GaussianNoise import GaussianNoise\n",
    "from analogvnn.nn.normalize.Clamp import Clamp\n",
    "from analogvnn.nn.precision.ReducePrecision import ReducePrecision\n",
    "from analogvnn.parameter.PseudoParameter import PseudoParameter\n",
    "from analogvnn.utils.is_cpu_cuda import is_cpu_cuda\n",
    "\n",
    "print(f\"AnalogVNN version: {analogvnn.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device, is_cuda = is_cpu_cuda.is_using_cuda\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "## Load a dataset\n",
    "\n",
    "Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FP5258xjs-v"
   },
   "outputs": [],
   "source": [
    "def load_vision_dataset(dataset, path, batch_size, is_cuda=False, grayscale=True):\n",
    "    dataset_kwargs = {\n",
    "        'batch_size': batch_size,\n",
    "        'shuffle': True\n",
    "    }\n",
    "\n",
    "    if is_cuda:\n",
    "        cuda_kwargs = {\n",
    "            'num_workers': 1,\n",
    "            'pin_memory': True,\n",
    "        }\n",
    "        dataset_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    if grayscale:\n",
    "        use_transform = transforms.Compose([\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    else:\n",
    "        use_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_set = dataset(root=path, train=True, download=True, transform=use_transform)\n",
    "    test_set = dataset(root=path, train=False, download=True, transform=use_transform)\n",
    "    train_loader = DataLoader(train_set, **dataset_kwargs)\n",
    "    test_loader = DataLoader(test_set, **dataset_kwargs)\n",
    "\n",
    "    zeroth_element = next(iter(test_loader))[0]\n",
    "    input_shape = list(zeroth_element.shape)\n",
    "\n",
    "    return train_loader, test_loader, input_shape, tuple(train_set.classes)\n",
    "\n",
    "# Loading Data...\n",
    "print(f\"Loading Data...\")\n",
    "train_loader, test_loader, input_shape, classes = load_vision_dataset(\n",
    "    dataset=torchvision.datasets.MNIST,\n",
    "    path=\"_data/\",\n",
    "    batch_size=128,\n",
    "    is_cuda=is_cuda\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06PdU_iGVe16"
   },
   "source": [
    "## Build a 3 layered linear photonic analog neural network\n",
    "\n",
    "`FullSequential` is sequential model where backward graph is the reverse of forward graph.\n",
    "\n",
    "To add the Reduce Precision, Normalization, and Noise before and after the main Linear layer, `add_layer` function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "class LinearModel(FullSequential):\n",
    "    def __init__(self, activation_class, norm_class, precision_class, precision, noise_class, leakage):\n",
    "        super(LinearModel, self).__init__()\n",
    "\n",
    "        self.activation_class = activation_class\n",
    "        self.norm_class = norm_class\n",
    "        self.precision_class = precision_class\n",
    "        self.precision = precision\n",
    "        self.noise_class = noise_class\n",
    "        self.leakage = leakage\n",
    "\n",
    "        self.all_layers = []\n",
    "        self.all_layers.append(nn.Flatten(start_dim=1))\n",
    "        self.add_layer(Linear(in_features=28 * 28, out_features=256))\n",
    "        self.add_layer(Linear(in_features=256, out_features=128))\n",
    "        self.add_layer(Linear(in_features=128, out_features=10))\n",
    "\n",
    "        self.add_sequence(*self.all_layers)\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        self.all_layers.append(self.norm_class())\n",
    "        self.all_layers.append(self.precision_class(precision=self.precision))\n",
    "        self.all_layers.append(self.noise_class(leakage=self.leakage, precision=self.precision))\n",
    "        self.all_layers.append(layer)\n",
    "        self.all_layers.append(self.noise_class(leakage=self.leakage, precision=self.precision))\n",
    "        self.all_layers.append(self.norm_class())\n",
    "        self.all_layers.append(self.precision_class(precision=self.precision))\n",
    "        self.all_layers.append(self.activation_class())\n",
    "        self.activation_class.initialise_(layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: analogvnn.nn.module.Sequential.Sequential.add_sequence() is used to create and set forward and backward graphs in AnalogVNN, more information in Inner Workings"
   ],
   "metadata": {
    "id": "iOkIKXWoZbmn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "nn_model = LinearModel(\n",
    "    activation_class=GeLU,\n",
    "    norm_class=Clamp,\n",
    "    precision_class=ReducePrecision,\n",
    "    precision=2 ** 4,\n",
    "    noise_class=GaussianNoise,\n",
    "    leakage=0.2\n",
    ")\n",
    "print(nn_model)"
   ],
   "metadata": {
    "id": "39SIO0ICWiJ2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPZ68wASog_I"
   },
   "source": [
    "## Build a WeightModel \n",
    "\n",
    "WeightModel is use to parametrize the parameter of LinearModel to simulate photonic weights\n",
    "\n",
    "`FullSequential` is sequential model where backward graph is the reverse of forward graph."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class WeightModel(FullSequential):\n",
    "    def __init__(self, norm_class, precision_class, precision, noise_class, leakage):\n",
    "        super(WeightModel, self).__init__()\n",
    "        self.all_layers = []\n",
    "\n",
    "        self.all_layers.append(norm_class())\n",
    "        self.all_layers.append(precision_class(precision=precision))\n",
    "        self.all_layers.append(noise_class(leakage=leakage, precision=precision))\n",
    "\n",
    "        self.eval()\n",
    "        self.add_sequence(*self.all_layers)"
   ],
   "metadata": {
    "id": "tcN3WT8zWXQv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: Since the “WeightModel” will only be used for converting the data to analog data to be used in the main “ LinearModel”, we can use “eval()” to make sure the “WeightModel” is never been trained"
   ],
   "metadata": {
    "id": "Dsudt6dXZBnV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "weight_model = WeightModel(\n",
    "    norm_class=Clamp,\n",
    "    precision_class=ReducePrecision,\n",
    "    precision=2 ** 4,\n",
    "    noise_class=GaussianNoise,\n",
    "    leakage=0.2\n",
    ")\n",
    "print(weight_model)"
   ],
   "metadata": {
    "id": "FgehAu7qWlyV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using PseudoParameter to parametrize the parameter"
   ],
   "metadata": {
    "id": "Dtg27Y80WwR0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "PseudoParameter.parametrize_module(nn_model, transformation=weight_model)"
   ],
   "metadata": {
    "id": "O8i_yEZHWpZb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix4mEL65on-w"
   },
   "source": [
    "## Adding accuracy, loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def cross_entropy_accuracy(output, target) -> float:\n",
    "    _, preds = torch.max(output.data, 1)\n",
    "    correct = (preds == target).sum().item()\n",
    "    return correct / len(output)"
   ],
   "metadata": {
    "id": "bL9owooIXaJ2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "nn_model.loss_function = nn.CrossEntropyLoss()\n",
    "nn_model.accuracy_function = cross_entropy_accuracy\n",
    "nn_model.optimizer = optim.Adam(params=nn_model.parameters())"
   ],
   "metadata": {
    "id": "XnWd-loMXfLj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txh1-HanXkzC"
   },
   "source": [
    "## Compiling the Models"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "nn_model.compile(device=device)\n",
    "weight_model.compile(device=device)\n",
    "print(\"Compiled\")"
   ],
   "metadata": {
    "id": "wbmpzLWpXo5t"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0BBx6D4XExj"
   },
   "source": [
    "## Train and evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(10):\n",
    "    train_loss, train_accuracy = nn_model.train_on(train_loader, epoch=epoch)\n",
    "    test_loss, test_accuracy = nn_model.test_on(test_loader, epoch=epoch)\n",
    "\n",
    "    str_epoch = str(epoch + 1).zfill(1)\n",
    "    print_str = f'({str_epoch})' \\\n",
    "                f' Training Loss: {train_loss:.4f},' \\\n",
    "                f' Training Accuracy: {100. * train_accuracy:.0f}%,' \\\n",
    "                f' Testing Loss: {test_loss:.4f},' \\\n",
    "                f' Testing Accuracy: {100. * test_accuracy:.0f}%\\n'\n",
    "    print(print_str)"
   ],
   "metadata": {
    "id": "9cAdBEaXX51G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-47O6_GLdRuT"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You have trained a 3 layered linear photonic analog neural network with 4-bit precision, 0.2 leakage and clamp normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "GitHub: [https://github.com/Vivswan/AnalogVNN](https://github.com/Vivswan/AnalogVNN)\n",
    "\n",
    "Documentation: [https://analogvnn.readthedocs.io/](https://analogvnn.readthedocs.io/)"
   ],
   "metadata": {
    "id": "gic6z7KcYo1h"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
